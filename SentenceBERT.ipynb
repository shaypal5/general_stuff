{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shaypal5/general_stuff/blob/master/SentenceBERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOzAKFdbUmyP"
      },
      "source": [
        "**Basic Semantic Search Using Sentence Embeddings** \\\\\n",
        "Sematically Similarity Using fine tuned pre-trained BERT."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oedDvAy3M4jd"
      },
      "source": [
        "**Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks** \\\\\n",
        "[GitHub](https://github.com/UKPLab/sentence-transformers) \\\\\n",
        "[Paper](https://arxiv.org/pdf/1908.10084.pdf) \\\\\n",
        "Sentence-BERT (SBERT), a modification of the pretrained\n",
        "BERT network that use siamese and triplet network structures to derive semantically meaningful sentence embeddings that can be compared using cosine-similarity. This reduces the\n",
        "effort for finding the most similar pair from 65\n",
        "hours with BERT / RoBERTa to about 5 seconds with SBERT, while maintaining the accuracy from BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xHlXt5zMveR"
      },
      "source": [
        "**Installation and Enviornment Setup**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oj9GjZZIMwPB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "78506d46-f7aa-418c-8c71-333283a01c14"
      },
      "source": [
        "!pip install -U sentence-transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: sentence-transformers in /usr/local/lib/python3.6/dist-packages (0.2.6.1)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: nltk in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (3.2.5)\n",
            "Requirement already satisfied, skipping upgrade: transformers>=2.8.0 in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (2.11.0)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: torch>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.5.0+cu101)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sentence-transformers) (0.15.1)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from nltk->sentence-transformers) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.6/dist-packages (from transformers>=2.8.0->sentence-transformers) (20.4)\n",
            "Requirement already satisfied, skipping upgrade: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers>=2.8.0->sentence-transformers) (0.0.43)\n",
            "Requirement already satisfied, skipping upgrade: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers>=2.8.0->sentence-transformers) (0.7)\n",
            "Requirement already satisfied, skipping upgrade: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers>=2.8.0->sentence-transformers) (0.1.91)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from transformers>=2.8.0->sentence-transformers) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers>=2.8.0->sentence-transformers) (2019.12.20)\n",
            "Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.6/dist-packages (from transformers>=2.8.0->sentence-transformers) (3.0.12)\n",
            "Requirement already satisfied, skipping upgrade: tokenizers==0.7.0 in /usr/local/lib/python3.6/dist-packages (from transformers>=2.8.0->sentence-transformers) (0.7.0)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.1->sentence-transformers) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers>=2.8.0->sentence-transformers) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=2.8.0->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.8.0->sentence-transformers) (2.9)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.8.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.8.0->sentence-transformers) (2020.4.5.2)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.8.0->sentence-transformers) (1.24.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DE331XNHMnha"
      },
      "source": [
        "**Sentences Embedding with a Pretrained Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulMBhMRxMjNC"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twn5-N6YNtFc"
      },
      "source": [
        "\n",
        "The models were first fine-tuned on the AllNLI dataset, then on train set of STS benchmark. They are specifically well suited for semantic textual similarity. For more details, see: sts-models.md.\n",
        "\n",
        "**Pretrained Models** \\\\\n",
        "bert-base-nli-stsb-mean-tokens: Performance: STSbenchmark: 85.14 \\\\\n",
        "bert-large-nli-stsb-mean-tokens: Performance: STSbenchmark: 85.29 \\\\\n",
        "roberta-base-nli-stsb-mean-tokens: Performance: STSbenchmark: 85.44 \\\\\n",
        "roberta-large-nli-stsb-mean-tokens: Performance: STSbenchmark: 86.39 \\\\\n",
        "distilbert-base-nli-stsb-mean-tokens: Performance: STSbenchmark: 84.38 \\\\\n",
        "**Source: \"*Github Repository*\"**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yx6BoYDXNfSW"
      },
      "source": [
        "model = SentenceTransformer('bert-base-nli-mean-tokens')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdwTSHbNOH2w"
      },
      "source": [
        "sentences = ['Absence of sanity',\n",
        "             'Lack of saneness',\n",
        "             'A man is eating food.',\n",
        "             'A man is eating a piece of bread.',\n",
        "             'The girl is carrying a baby.',\n",
        "             'A man is riding a horse.',\n",
        "             'A woman is playing violin.',\n",
        "             'Two men pushed carts through the woods.',\n",
        "             'A man is riding a white horse on an enclosed ground.',\n",
        "             'A monkey is playing drums.',\n",
        "             'A cheetah is running behind its prey.']\n",
        "sentence_embeddings_base = model.encode(sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZhHjplkOcQM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 809
        },
        "outputId": "46d4f14d-aea9-4734-b489-ef947b127772"
      },
      "source": [
        "for sentence, embedding in zip(sentences, sentence_embeddings):\n",
        "    print(\"Sentence:\", sentence)\n",
        "    print(\"Embedding:\", embedding)\n",
        "    print(\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence: Absence of sanity\n",
            "Embedding: [-0.32751286  0.61889     0.79470986 ...  0.02687939 -0.13736466\n",
            "  2.2358234 ]\n",
            "\n",
            "Sentence: Lack of saneness\n",
            "Embedding: [-0.13622051  0.41023704  0.73581094 ... -0.19232634 -0.12812541\n",
            "  1.9241054 ]\n",
            "\n",
            "Sentence: A man is eating food.\n",
            "Embedding: [-0.20701389  0.6842224  -0.6645474  ... -0.16564319 -1.1139905\n",
            "  0.93136346]\n",
            "\n",
            "Sentence: A man is eating a piece of bread.\n",
            "Embedding: [-0.5298074   1.0654029  -0.6272791  ... -0.31372124 -0.42181608\n",
            " -0.10556436]\n",
            "\n",
            "Sentence: The girl is carrying a baby.\n",
            "Embedding: [ 0.0217128   0.62021583 -0.9170204  ... -0.16280569  1.2698941\n",
            "  1.9319594 ]\n",
            "\n",
            "Sentence: A man is riding a horse.\n",
            "Embedding: [-0.54099154 -0.17697512 -0.13467026 ... -1.097092   -0.5963547\n",
            "  1.5534692 ]\n",
            "\n",
            "Sentence: A woman is playing violin.\n",
            "Embedding: [-0.11929066 -0.04466006 -1.2879481  ...  0.3768997  -0.9470354\n",
            "  1.0744518 ]\n",
            "\n",
            "Sentence: Two men pushed carts through the woods.\n",
            "Embedding: [ 0.0423027   0.07625704 -0.09663814 ... -0.08406684 -0.32605657\n",
            "  1.1914703 ]\n",
            "\n",
            "Sentence: A man is riding a white horse on an enclosed ground.\n",
            "Embedding: [ 0.05905828 -0.06080583 -0.4062164  ... -0.49742523 -0.22286515\n",
            "  0.6714216 ]\n",
            "\n",
            "Sentence: A monkey is playing drums.\n",
            "Embedding: [-0.8173298   0.11483686  0.08017533 ... -0.4906762  -0.2627806\n",
            "  0.47130343]\n",
            "\n",
            "Sentence: A cheetah is running behind its prey.\n",
            "Embedding: [-0.02438198 -0.508697   -1.2986976  ... -0.6954341   0.60762763\n",
            "  0.8320411 ]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTaHpfAMPBor"
      },
      "source": [
        "Each sentence embedding have a shape of [768 x 1]. \\\\\n",
        "Let's play some more with other pre-trained model, for e.g \"roberta-large-nli-mean-tokens\". Let's have a look.  \n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MSHATDVO5y8"
      },
      "source": [
        "model_roberta = SentenceTransformer('roberta-large-nli-mean-tokens')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAlMx99VPtuS"
      },
      "source": [
        "sentences = ['Absence of sanity',\n",
        "             'Lack of saneness',\n",
        "             'A man is eating food.',\n",
        "             'A man is eating a piece of bread.',\n",
        "             'The girl is carrying a baby.',\n",
        "             'A man is riding a horse.',\n",
        "             'A woman is playing violin.',\n",
        "             'Two men pushed carts through the woods.',\n",
        "             'A man is riding a white horse on an enclosed ground.',\n",
        "             'A monkey is playing drums.',\n",
        "             'A cheetah is running behind its prey.']\n",
        "sentence_embeddings = model_roberta.encode(sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IbfI1VbQera",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 809
        },
        "outputId": "d21aa31e-d3ad-4592-a3c6-9d87299889af"
      },
      "source": [
        "for sentence, embedding in zip(sentences, sentence_embeddings):\n",
        "    print(\"Sentence:\", sentence)\n",
        "    print(\"Embedding:\", embedding)\n",
        "    print(\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence: Absence of sanity\n",
            "Embedding: [-0.32751286  0.61889     0.79470986 ...  0.02687939 -0.13736466\n",
            "  2.2358234 ]\n",
            "\n",
            "Sentence: Lack of saneness\n",
            "Embedding: [-0.13622051  0.41023704  0.73581094 ... -0.19232634 -0.12812541\n",
            "  1.9241054 ]\n",
            "\n",
            "Sentence: A man is eating food.\n",
            "Embedding: [-0.20701389  0.6842224  -0.6645474  ... -0.16564319 -1.1139905\n",
            "  0.93136346]\n",
            "\n",
            "Sentence: A man is eating a piece of bread.\n",
            "Embedding: [-0.5298074   1.0654029  -0.6272791  ... -0.31372124 -0.42181608\n",
            " -0.10556436]\n",
            "\n",
            "Sentence: The girl is carrying a baby.\n",
            "Embedding: [ 0.0217128   0.62021583 -0.9170204  ... -0.16280569  1.2698941\n",
            "  1.9319594 ]\n",
            "\n",
            "Sentence: A man is riding a horse.\n",
            "Embedding: [-0.54099154 -0.17697512 -0.13467026 ... -1.097092   -0.5963547\n",
            "  1.5534692 ]\n",
            "\n",
            "Sentence: A woman is playing violin.\n",
            "Embedding: [-0.11929066 -0.04466006 -1.2879481  ...  0.3768997  -0.9470354\n",
            "  1.0744518 ]\n",
            "\n",
            "Sentence: Two men pushed carts through the woods.\n",
            "Embedding: [ 0.0423027   0.07625704 -0.09663814 ... -0.08406684 -0.32605657\n",
            "  1.1914703 ]\n",
            "\n",
            "Sentence: A man is riding a white horse on an enclosed ground.\n",
            "Embedding: [ 0.05905828 -0.06080583 -0.4062164  ... -0.49742523 -0.22286515\n",
            "  0.6714216 ]\n",
            "\n",
            "Sentence: A monkey is playing drums.\n",
            "Embedding: [-0.8173298   0.11483686  0.08017533 ... -0.4906762  -0.2627806\n",
            "  0.47130343]\n",
            "\n",
            "Sentence: A cheetah is running behind its prey.\n",
            "Embedding: [-0.02438198 -0.508697   -1.2986976  ... -0.6954341   0.60762763\n",
            "  0.8320411 ]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoHQPs5RQk70"
      },
      "source": [
        "**Semantic Search** Using Sentence-BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bntpkqIvQf0S"
      },
      "source": [
        "query = 'Nobody has sane thoughts'  #  A query sentence uses for searching semantic similarity score.\n",
        "queries = [query]\n",
        "query_embeddings = model.encode(queries)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8ZaHU0OR984",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "1f93a5a1-eb48-4529-af7b-035bcc215301"
      },
      "source": [
        "!pip install scipy\n",
        "import scipy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy) (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZBrN6ROReys",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "20d12a14-2f25-4fd6-ea6e-592fb3a46bee"
      },
      "source": [
        "print(\"Semantic Search Results\")\n",
        "\n",
        "for query, query_embedding in zip(queries, query_embeddings):\n",
        "    distances = scipy.spatial.distance.cdist([query_embedding], sentence_embeddings_base, \"cosine\")[0]\n",
        "\n",
        "    results = zip(range(len(distances)), distances)\n",
        "    results = sorted(results, key=lambda x: x[1])\n",
        "    print(\"Query:\", query)\n",
        "    print(\"\\nTop 5 most similar sentences in corpus:\")\n",
        "\n",
        "    for idx, distance in results[0:number_top_matches]:\n",
        "        print(sentences[idx].strip(), \"(Cosine Score: %.4f)\" % (1-distance))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Semantic Search Results\n",
            "Query: Nobody has sane thoughts\n",
            "\n",
            "Top 5 most similar sentences in corpus:\n",
            "Lack of saneness (Cosine Score: 0.8958)\n",
            "Absence of sanity (Cosine Score: 0.8744)\n",
            "A man is riding a horse. (Cosine Score: 0.1705)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}